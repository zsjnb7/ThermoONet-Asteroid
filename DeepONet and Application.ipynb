{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849a7883-afe7-4bd7-9403-64b49875c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb8d5592-1379-49f9-aa88-8ce50f52f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following is the architecture of DeepONet\n",
    "# Note that it is necessary to run the code in GPU for rapid computation\n",
    "# This requires to install the PyTorch that matches with your own computer's GPU\n",
    "# The step is simple to follow the method of PyTorch official\n",
    "\n",
    "num_sensors = 128\n",
    "num_input = 32\n",
    "std_a = 0.26688421024274595\n",
    "mean_a = 0.6380248110311998\n",
    "\n",
    "# Construct a channel attention mechanism module (more sensitive to features)\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=6):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.BatchNorm1d(channel // reduction, affine=True),\n",
    "            nn.LeakyReLU(0, inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=True),\n",
    "            nn.BatchNorm1d(channel, affine=True),\n",
    "            nn.Sigmoid())\n",
    "        self.fco = nn.Linear(channel, channel, bias=True)\n",
    "        self.bn1 = nn.BatchNorm1d(channel, affine=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        y1 = self.fc1(input)\n",
    "        y2 = self.bn1(self.fco(torch.mul(y1, input))+input)\n",
    "        return y2\n",
    "    \n",
    "class SELayer_w(nn.Module):\n",
    "    def __init__(self, channel, reduction=6):\n",
    "        super(SELayer_w, self).__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.BatchNorm1d(channel // reduction, affine=True),\n",
    "            nn.LeakyReLU(0, inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=True),\n",
    "            nn.BatchNorm1d(channel, affine=True),\n",
    "            nn.Sigmoid())\n",
    "        self.fco = nn.Linear(channel, channel, bias=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        y1 = self.fc1(input)\n",
    "        y2 = self.fco(torch.mul(y1, input))+input\n",
    "        return y2\n",
    "    \n",
    "# Branch networks\n",
    "# Input dimension for branch net1: [batchsize*num_input, num_sensors]\n",
    "# Input dimension for branch net2: [batchsize*num_input, 1]\n",
    "# Output dimension: [batchsize*num_input, self-define]\n",
    "# Here self-define is suggested to be taken 64\n",
    "\n",
    "class Branch1(nn.Module):\n",
    "    # branch net1\n",
    "    def __init__(self, num_sensors):\n",
    "        super(Branch1, self).__init__()\n",
    "        self.numinput = num_input\n",
    "        self.numsensors = num_sensors\n",
    "        self.net = self.__NET__(128, 4)\n",
    "    \n",
    "    def __NET__(self, nc, nb):\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(nn.Linear(self.numsensors, nc, bias=False))\n",
    "        layers.append(nn.BatchNorm1d(nc, affine=True))\n",
    "        layers.append(nn.LeakyReLU(0.02, inplace=True))\n",
    "        for i in range(nb):\n",
    "            layers.append(SELayer(nc))\n",
    "        layers.append(nn.Linear(nc, 64, bias=True))\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        output = self.net(input)\n",
    "        return output\n",
    "    \n",
    "class Branch2(nn.Module):\n",
    "    # branch net2\n",
    "    def __init__(self, num_sensors):\n",
    "        super(Branch2, self).__init__()\n",
    "        self.numinput = num_input\n",
    "        self.numsensors = num_sensors\n",
    "        self.net = self.__NET__(128, 2)\n",
    "    \n",
    "    def __NET__(self, nc, nb):\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(nn.Linear(1, nc, bias=False))\n",
    "        layers.append(nn.BatchNorm1d(nc, affine=True))\n",
    "        layers.append(nn.LeakyReLU(0.02, inplace=True))\n",
    "        for i in range(nb):\n",
    "            layers.append(SELayer(nc))\n",
    "        layers.append(nn.Linear(nc, 64, bias=True))\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        output = self.net(input)\n",
    "        return output\n",
    "    \n",
    "class Branch(nn.Module):\n",
    "    # output of brach net1 and branch net2\n",
    "    def __init__(self, num_sensors):\n",
    "        super(Branch, self).__init__()\n",
    "        self.branch1 = Branch1(num_sensors)\n",
    "        self.branch2 = Branch2(num_sensors)\n",
    "        self.se = SELayer_w(64)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                \n",
    "                nn.init.normal_(m.weight.data, 0, 0.02)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    def forward(self, input1, input2):\n",
    "        \n",
    "        output1 = self.branch1(input1)\n",
    "        output2 = self.branch2(input2)\n",
    "        output = torch.mul(output1, output2)+0.001\n",
    "        return self.se(output)\n",
    "    \n",
    "# Trunk network\n",
    "# Input dimension: [batchsize*num_input, 1]\n",
    "# Output dimension: [batchsize*num_input, self-define]\n",
    "# Here self-define is suggested to be taken 64\n",
    "\n",
    "class Trunk(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Trunk, self).__init__()\n",
    "        self.net = self.__NET__(128, 1)\n",
    "    \n",
    "    def __NET__(self, nc, nb):\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(nn.Linear(1, nc, bias=False))\n",
    "        layers.append(nn.BatchNorm1d(nc, affine=True))\n",
    "        layers.append(nn.LeakyReLU(0.02, inplace=True))\n",
    "        for i in range(nb):\n",
    "            layers.append(SELayer(nc))\n",
    "        layers.append(nn.Linear(nc, 64, bias=False))\n",
    "        layers.append(nn.BatchNorm1d(64, affine=True))\n",
    "        layers.append(nn.LeakyReLU(0.02, inplace=True))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                \n",
    "                nn.init.normal_(m.weight.data, 0, 0.02)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        output = self.net(input)\n",
    "        return output\n",
    "\n",
    "# Read the specific parameters of the networks\n",
    "# Note that the file path need to be reselected in different environment (it is simple to understand)\n",
    "# We suggest retrain the network for better using in the problem that you need to solve \n",
    "# The detail training code is not provided in this file\n",
    "\n",
    "trunk = torch.load(\"net_data/trunk_sigmoid_whole.pkl\")\n",
    "branch = torch.load(\"net_data/branch_sigmoid_whole.pkl\")\n",
    "\n",
    "# Close BN\n",
    "\n",
    "branch.eval();\n",
    "trunk.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcac35bd-7dc2-4430-8a4c-d2d3260f3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The class for calculating the Yarkovsky database in spherical coordinate frame of convex polyhedron asteroids\n",
    "\n",
    "# The input is\n",
    "\n",
    "# branch: the branch networks of DeepONet\n",
    "\n",
    "# trunk: the trunk networks of DeepONet\n",
    "\n",
    "# para: the combination of physical parameters\n",
    "# the suggested order is\n",
    "# [rotation speed (s^-1)\n",
    "#  Bond albedo \n",
    "#  emissivity\n",
    "#  incident solar radiation flux at 1 au (W/m^2)\n",
    "#  Stefan–Boltzmann constant (W m^-2 K^-4)\n",
    "#  surface density (kg/m^3)\n",
    "#  specific heat capacity (J K^-1 kg^-1)\n",
    "#  thermal conductivity (W m^-1 K^-1)\n",
    "#  length unit of facet (m)\n",
    "#  quality (kg)]\n",
    "\n",
    "# shape: the file path of txt file containing points and combinations.\n",
    "# the suggested order is\n",
    "# [points\n",
    "#  combination methods]\n",
    "\n",
    "class Yarkovsky_database():\n",
    "    def __init__(self, branch, trunk, para, shape):\n",
    "        self.branch = branch\n",
    "        self.trunk = trunk\n",
    "        self.para = para\n",
    "        self.shape = shape\n",
    "        \n",
    "    def __normal__(self, f, mean, std):\n",
    "        # Z-score\n",
    "        \n",
    "        return (f-mean)/std\n",
    "    \n",
    "    # Following is some computions of the triangles properties\n",
    "    # A, B, C are three space point coordinates of triangles\n",
    "\n",
    "    def __normal_vector__(self, A, B, C):\n",
    "        # calculate the normal vectors of facets\n",
    "        \n",
    "        AB = B-A\n",
    "        AC = C-A\n",
    "        nv = np.cross(AB, AC)\n",
    "        return nv/np.sqrt(np.sum(nv**2))\n",
    "\n",
    "    def __center_vector__(self, A, B, C):\n",
    "        # calculate the barycenter of facets\n",
    "        \n",
    "        Cx = (A[0]+B[0]+C[0])/3\n",
    "        Cy = (A[1]+B[1]+C[1])/3\n",
    "        Cz = (A[2]+B[2]+C[2])/3\n",
    "        return np.array([Cx, Cy, Cz])\n",
    "\n",
    "    def __area_surface__(self, A, B, C):\n",
    "        # calculate the areas of facets\n",
    "        \n",
    "        v1 = B-A\n",
    "        v2 = C-A\n",
    "        cross_product = np.cross(v1, v2)\n",
    "        area = 0.5*np.linalg.norm(cross_product)\n",
    "        return area\n",
    "    \n",
    "    # Following is the calculations for specific asteroids\n",
    "    \n",
    "    def __shape_data__(self):\n",
    "        # parse the input shape data\n",
    "        \n",
    "        point_data = np.loadtxt(self.shape[0])\n",
    "        combine_method = np.loadtxt(self.shape[1])\n",
    "        \n",
    "        surface_element = []\n",
    "        for i in range(len(combine_method)):\n",
    "            surface_element.append([point_data[int(combine_method[i, 0])-1, :], point_data[int(combine_method[i, 1])-1, :], \n",
    "                                    point_data[int(combine_method[i, 2])-1, :]])\n",
    "        surface_element = np.array(surface_element)\n",
    "\n",
    "        nvs = []\n",
    "        ces = []\n",
    "        ars = []\n",
    "        for i in range(len(surface_element)):\n",
    "            nv = self.__normal_vector__(surface_element[i, 0, :], surface_element[i, 1, :], surface_element[i, 2, :])\n",
    "            ce = self.__center_vector__(surface_element[i, 0, :], surface_element[i, 1, :], surface_element[i, 2, :])\n",
    "            ar = self.__area_surface__(surface_element[i, 0, :], surface_element[i, 1, :], surface_element[i, 2, :])\n",
    "            nvs.append(nv)\n",
    "            ces.append(ce)\n",
    "            ars.append(ar)\n",
    "        nvs = np.array(nvs)\n",
    "        ces = np.array(ces)\n",
    "        ars = np.array(ars).reshape(len(surface_element), 1)\n",
    "\n",
    "        surface = [nvs, ars]\n",
    "        return surface\n",
    "\n",
    "    def __fl__(self, beta, yita, nvs):\n",
    "        # calculate the radiation flux function of every facet in spin axis coordinate system\n",
    "        \n",
    "        # beta: the angle between the Sun and z-axis\n",
    "        # yita: the angle between the Sun and x-axis\n",
    "        # nvs: the normal vectors of facets\n",
    "        \n",
    "        N = 128\n",
    "        sun = np.array([np.sin(beta)*np.cos(yita), np.sin(beta)*np.sin(yita), np.cos(beta)])\n",
    "        if np.sqrt(sun[0]**2+sun[1]**2)==0:\n",
    "            lo_sun = np.arccos(0)\n",
    "        else:\n",
    "            lo_sun = np.arccos(sun[0]/np.sqrt(sun[0]**2+sun[1]**2))\n",
    "        if yita > 180*np.pi/180:\n",
    "            if np.sqrt(sun[0]**2+sun[1]**2)==0:\n",
    "                lo_sun = 2*np.pi-np.arccos(0)\n",
    "            else:\n",
    "                lo_sun = 2*np.pi-np.arccos(sun[0]/np.sqrt(sun[0]**2+sun[1]**2))\n",
    "        sun_xy = np.sqrt(sun[0]**2+sun[1]**2)\n",
    "        sun = np.array([sun_xy*np.cos(lo_sun-np.linspace(0, 2*np.pi, N)), \\\n",
    "                        sun_xy*np.sin(lo_sun-np.linspace(0, 2*np.pi, N)), \\\n",
    "                        sun[2]*np.ones(N)]).T\n",
    "        \n",
    "        function = np.dot(nvs, sun.T)\n",
    "        function[function<0] = 0\n",
    "\n",
    "        flist_ellipsoid = interp1d(np.linspace(0, 2*np.pi, N), function, kind='linear', axis=1)\n",
    "\n",
    "        return flist_ellipsoid\n",
    "        \n",
    "    def yarkovsky(self, r):\n",
    "        # calculate the Yarkovsky acceleration database\n",
    "        # r: the range of heliocentric distance that the database needs\n",
    "        # denoted as [min, max, grid number]\n",
    "        \n",
    "        [min_beta, max_beta, num_b] = [0, np.pi, 128]       # here you can modify the grid numbers\n",
    "        [min_yita, max_yita, num_y] = [0, 2*np.pi, 128]     # such as 100, 200, but it is suggested to be taken as 128\n",
    "        [min_r, max_r, num_r] = r\n",
    "        [omega, A, eps, S, sig, rho, C, kapa, R, m] = self.para\n",
    "        ft = np.sqrt(rho*C*kapa)\n",
    "        [nvs, ars] = self.__shape_data__()\n",
    "        \n",
    "        flist_ellipsoid_list = []\n",
    "        for beta in np.arange(min_beta, max_beta+(max_beta-min_beta)/(num_b-1), \n",
    "                              (max_beta-min_beta)/(num_b-1)):\n",
    "            flist_ellipsoid = self.__fl__(beta, 0, nvs)\n",
    "            flist_ellipsoid_list.append(flist_ellipsoid)\n",
    "        \n",
    "        p_list = []\n",
    "        Te_list = []\n",
    "        for r in np.arange(min_r, max_r+(max_r-min_r)/(num_r-1), (max_r-min_r)/(num_r-1)):\n",
    "            Te = np.sqrt(np.sqrt(((1-A)*S/(r**2*eps*sig))))\n",
    "            phi = ft*np.sqrt(omega)/(eps*sig*Te**3)\n",
    "            p_list.append(phi)\n",
    "            Te_list.append(Te)\n",
    "        Te_a = np.array(Te_list)\n",
    "        p_test = torch.tensor(np.array(p_list)).reshape(num_r, 1).float().cuda()\n",
    "        y_test = torch.zeros(1).reshape(1, 1).float().cuda()\n",
    "\n",
    "        out2 = branch.branch2(p_test)\n",
    "        out3 = trunk(y_test)\n",
    "\n",
    "        ay_list_plot = []\n",
    "        zsj = 0\n",
    "        for yita in np.arange(min_yita, max_yita+(max_yita-min_yita)/(num_y-1), (max_yita-min_yita)/(num_y-1)):\n",
    "            t = np.mod(np.linspace(0, 2*np.pi, 128)-yita, 2*np.pi)\n",
    "            ffn_t_or = np.array([flist_ellipsoid(t) for flist_ellipsoid in flist_ellipsoid_list])\n",
    "            ffn_t = torch.tensor(ffn_t_or).float().cuda()\n",
    "    \n",
    "            f_test = ffn_t.reshape(num_b*len(nvs), 128)\n",
    "            out1 = branch.branch1(f_test)\n",
    "    \n",
    "            ir = 0\n",
    "            for r in np.arange(min_r, max_r+(max_r-min_r)/(num_r-1), (max_r-min_r)/(num_r-1)):\n",
    "                out_mid = torch.mul(out1, (out2[ir].reshape(1, 64))[:, np.newaxis, :]).reshape(num_b*len(nvs), 64)+0.001\n",
    "                out = branch.se(out_mid)\n",
    "\n",
    "                Guy = torch.mean(torch.mul(out, out3), dim=1).unsqueeze(1)+0.001\n",
    "                Guy_deal = Guy.detach().cpu().numpy()*std_a+mean_a\n",
    "                Results = Guy_deal.reshape(num_b, len(nvs), 1)*Te_a[ir]\n",
    "        \n",
    "                FF = np.sum((Results)**4*nvs*ars*R**2, axis=1)*eps*sig*2/3/(3*1e+8)\n",
    "                a_Yarkovsky = FF/m\n",
    "        \n",
    "                ay_list_plot.append(a_Yarkovsky)\n",
    "        \n",
    "                if zsj%50==0:\n",
    "                    print(\"progress：\", zsj/(num_y*num_r)*100, \"%\")\n",
    "        \n",
    "                zsj = zsj+1\n",
    "                ir = ir+1\n",
    "        ay_plot_zsj = -np.array(ay_list_plot).transpose(1, 0, 2).reshape(num_b, num_y, num_r, 3)\n",
    "        \n",
    "        return ay_plot_zsj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fdce812-9033-4050-81f7-a51cbcfa179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shape data of asteroids\n",
    "# The input is the file path of txt file containing points and combinations\n",
    "\n",
    "# Following is an example for Phaethon\n",
    "\n",
    "Phaethon1 = \"test_asteroid/Phaethon.txt\"\n",
    "Phaethon2 = \"test_asteroid/Phaethon2.txt\"\n",
    "shape = [Phaethon1, Phaethon2]\n",
    "\n",
    "# The physical parameters\n",
    "# The input is the combination of all parameters\n",
    "\n",
    "# Following is an example for Phaethon\n",
    "\n",
    "omega = 2*np.pi/(3.6*3600)\n",
    "A = 0.122\n",
    "eps = 0.9\n",
    "S = 1357\n",
    "sig = 5.67*1e-8\n",
    "rho = 1500\n",
    "C = 600\n",
    "kapa = 0.1\n",
    "R = 896.1883527847208\n",
    "m = 1e+15\n",
    "para = [omega, A, eps, S, sig, rho, C, kapa, R, m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4537522f-cd17-4ea9-851d-29ed22b93cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following is an example for using the class to calculate Yarkovsky acceleration database in orbital evolution\n",
    "\n",
    "Yd = Yarkovsky_database(branch, trunk, para, shape)\n",
    "r = [0.05, 2.7, 128]\n",
    "\n",
    "# The output is Yarkovsky acceleration \n",
    "# it consists of \n",
    "# [beta, yita, r, 3], meaning ax, ay and az in spin axis coordinate system\n",
    "\n",
    "yarkovsky_acc = Yd.yarkovsky(r)\n",
    "\n",
    "# The interpolation function can be ragarded as the database\n",
    "# Specifically, multidimensional interpolation can be used in integration\n",
    "# The detail integration code is not provided in this file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
